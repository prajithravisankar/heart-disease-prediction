# heart-disease-prediction
Predict heart disease risk using machine learning.

Here's a clean **project structure** for your `README.md` (formatted in Markdown):

```markdown
# Project Structure
heart-disease-prediction/  
â”œâ”€â”€ **data/**  
â”‚   â”œâ”€â”€ **raw/**               # Raw dataset (`project 2.csv`)
â”‚   â””â”€â”€ **processed/**         # Cleaned/preprocessed data (e.g., `cleaned_data.csv`)  
â”œâ”€â”€ **notebooks/**             # Jupyter notebooks for analysis  
â”‚   â”œâ”€â”€ `eda.ipynb`            # Exploratory Data Analysis  
â”‚   â””â”€â”€ `model_training.ipynb` # Model experiments and evaluation  
â”œâ”€â”€ **src/**                   # Python scripts  
â”‚   â”œâ”€â”€ `data_preprocessing.py` # Data cleaning/feature engineering  
â”‚   â”œâ”€â”€ `train_model.py`        # Model training and tuning  
â”‚   â””â”€â”€ `app.py`                # (Optional) CLI/Flask deployment if we have time
â”œâ”€â”€ **models/**                # Trained models (e.g., `random_forest.pkl`)  
â”œâ”€â”€ **results/**               # Visualizations, metrics, and reports  
â”‚   â”œâ”€â”€ `confusion_matrix.png`  
â”‚   â””â”€â”€ `feature_importance.png`  
â”œâ”€â”€ **requirements.txt**      # Python dependencies  
â”œâ”€â”€ **README.md**             # Project overview and instructions  
â””â”€â”€ **OTHERS**               # MIT License (or others if we need any)  
```

### **Key Directories Explained**  
- **`data/raw`**: Contains the original unprocessed dataset.  
- **`data/processed`**: Stores cleaned data after preprocessing.  
- **`notebooks`**: For exploratory analysis and model prototyping.  
- **`src`**: Reusable Python scripts for data cleaning, modeling, and deployment.  
- **`models`**: Saves trained models for later use.  
- **`results`**: Stores visualizations, performance metrics, and reports.  

### **Collaboration Notes**  
- Use branches `prajith-ravisankar` and `emilio-santamaria` and `lasombra7` 
- Merge changes into `dev` for daily collaboration after we agree on.  
- Final stable code goes into `main` (protected branch).

### **Phase 1: Project Setup & Planning (March 13)**

**Goal**: Initialize repository, define roles, and finalize requirements.

- [x]  **Main Todo 1.1: GitHub Setup**
    - [x]  ~~**Sub-todo 1.1.1**: Create a GitHub repository~~
    - [x]  ~~**Sub-todo 1.1.2**: Creat branches:~~
        - [x]  ~~`main`: Protected branch for final merges.~~
        - [x]  ~~`dev`: Shared development branch for daily work.~~
        - [x]  ~~`prajith-ravisankar`~~
        - [ ]  `emilio-santamaria` teammate has to create their branch and confirm.
        - [ ] `lasombra7` teammate has to accept the invite from Github and create their branch to start contributions
- [x]  ~~**Main Todo 1.2: Requirements Finalization**~~
    - [x]  ~~**Sub-todo 1.2.1**: Review the PDF requirements and start working on:~~
        ~~- Data cleaning steps (missing values, outliers).~~
        ~~- Models to compare (e.g., Logistic Regression, Random Forest, XGBoost).~~
        ~~- Metrics (accuracy, F1-score, AUC-ROC).~~
    - [x]  ~~**Sub-todo 1.2.2**: confirm on communication platform (we are using discord)~~

### **Phase 2: Data Preparation (March 14â€“16)**

**Goal**: Clean and preprocess the dataset.

- [ ]  **Main Todo 2.1: Data Cleaning**
    - [x]  ~~**Sub-todo 2.1.1**: Load `project 2.csv` and inspect for:~~
        - ~~Missing values (e.g., empty `Cholesterol` or `Blood Pressure` entries).~~
        - ~~Duplicate rows.~~
        - ~~what to do with outliers? not sureâ€¦~~
            - ~~(e.g., `Age` > 100, `Blood Pressure` > 200).~~
        - ~~etc~~â€¦
    - [ ]  **Sub-todo 2.1.2**: Handle missing values:
        - ðŸ†• Use **KNNImputer** or **IterativeImputer** for advanced imputation (from the PDF).
        - Impute with mean/median or drop rows (document your choice).
        - etcâ€¦
    - [ ]  **Sub-todo 2.1.3**: Encode categorical variables:
        - `Gender`: Male=0, Female=1.
        - `Chest Pain Type`: Use **one-hot encoding** (avoids ordinal bias, per PDF).
        - etcâ€¦
- [ ]  **Main Todo 2.2: Feature Engineering**
    - [ ]  **Sub-todo 2.2.1**: Split data into features (`X`) and target (`y`).
    - [ ]  **Sub-todo 2.2.2**: Scale numerical features:
        - Use **StandardScaler** (Z-score normalization) for algorithms like SVM or Logistic Regression.
    - [ ]  **Sub-todo 2.2.3**: **Feature selection**:
        - Use **SelectKBest** or **RFE** (Recursive Feature Elimination) to reduce dimensionality.
    - [ ]  **Sub-todo 2.2.4**: Save preprocessed data as `cleaned_data.csv`.